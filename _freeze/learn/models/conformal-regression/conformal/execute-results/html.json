{
  "hash": "7b7f386b09ebe9c3353618c9dee3c67a",
  "result": {
    "markdown": "---\ntitle: \"Prediction Intervals Usng Conformal Inference\"\nformat: html\nknitr:\n  opts_chunk:\n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.align: \"center\"\n\nfig-format: svg\n---\n\n\n\n\nWhat is conformal inference? It is a collection of statistical methods that are mostly used to construct prediction intervals for any type of regression or classification model. The basic idea revolves around some theory on how to construct probability statements for a population of data points. \n\nFor example, suppose we have collected a set of 1000 standard normal data points. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n\nset.seed(1)\nreference_data <- tibble(data = rnorm(1000))\n\nreference_data %>% \n  ggplot(aes(x = data)) +\n  geom_line(stat = \"density\")\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/normal-dist-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\nIf we had a new observation that we thought might be from the same distribution, how would we say (probabilistically) whether we think that it belongs to the original distribution? \n\nIf we thought that 1000 were a sufficient sample size, we might compute some quantiles of these data to define \"the mainstream of the data.\" Let's use the 5th and 95th quantiles to set boundaries that define what we would expect to see most of the time:   \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquants <- quantile(reference_data$data, probs = c(0.05, 0.95))\n\nreference_data %>% \n  ggplot(aes(x = data)) +\n  geom_line(stat = \"density\") + \n  geom_vline(xintercept = quants, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/normal-quant-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\nIf we were to get a new sample beyond these data, we would be able to say that we are about 90% sure that the new sample does not conform to the original distribution. This works under the assumption that the data are exchangeable. \n\nWe can apply this relatively simple idea to model predictions. Suppose we have a model created on a numeric outcome. If we make predictions on a data set we can compute the model residuals and create a sort of reference error distribution. If we compute a prediction on a new unknown sample, we could use center this reference distribution around its predicted value. For some confidence level, we now know the range of predicted values that \"conform\" to the reference distribution. That range can define our prediction interval. \n\nThere are a variety of ways to apply this concept (which is unsurprisingly more complex than that the above description). The probably package has implemented a few of them for regression models (classification methods are coming in the future). \n\nLet's make a simple example to illustrate the results. We'll simulate a data set with a single predictor along with some unknown samples: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmake_data <- function(n, std_dev = 1 / 5) {\n  tibble(x = runif(n, min = -1)) %>%\n    mutate(\n      y = (x^3) + 2 * exp(-6 * (x - 0.3)^2),\n      y = y + rnorm(n, sd = std_dev)\n    )\n}\n\nn <- 1000\nset.seed(8383)\ntrain_data <- make_data(n)\n\ntrain_data %>% \n  ggplot(aes(x, y )) + \n  geom_point(alpha = 1 / 10)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/example-data-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\nWe'll use these data as a training set and fit a model: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(484)\nnnet_wflow <- \n  workflow(y ~ x, mlp(hidden_units = 4) %>% set_mode(\"regression\"))\n\nnnet_fit <- nnet_wflow %>% fit(train_data)\nnnet_pred <- augment(nnet_fit, train_data)\n\ntrain_data %>% \n  ggplot(aes(x)) + \n  geom_point(aes(y = y), alpha = 1 / 10) +\n  geom_line(data = nnet_pred, aes(y = .pred),\n            linewidth = 1, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/model-fit-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\n## Split Conformal Inference\n\nThe most simple approach is to reserve some data specifically for estimating the residual distribution. We know that simply re-predicting the training set is a bad idea; the residuals would be smaller than they should be since the same data are used to create the model and to evaluate the model. \n\nLet's simulate another data set containing 250 samples and call that the \"calibration set\". These data can be predicted and their residuals can be used to define what conforms to model. We'll also create a large test set to see if we've done a good job. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7292)\ncal_data  <- make_data(250)\ntest_data <- make_data(10000)\n```\n:::\n\n\nThe probably package has a set of functions with the prefix `int_conformal` that can be used to create prediction intervals. One is: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsplit_int <- int_conformal_infer_split(nnet_fit, cal_data)\nsplit_int\n#> Split Conformal inference\n#> preprocessor: formula \n#> model: mlp (engine = nnet) \n#> calibration set size: 250 \n#> \n#> Use `predict(object, new_data, level)` to compute prediction intervals\n```\n:::\n\n\nTo get predictions on new data, we use the standard `predict()` method on this object: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Produce 90% prediction intervals\ntest_split_res <- \n  predict(split_int, test_data, level = 0.90) %>% \n  bind_cols(test_data)\n```\n:::\n\n\nThe results: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntest_split_res %>% \n  ggplot(aes(x)) +\n  geom_point(aes(y = y), alpha = 1 / 20) +\n  geom_line(\n    data = nnet_pred, aes(y = .pred),\n    linewidth = 1, col = \"blue\"\n  ) +\n  geom_ribbon(aes(ymin = .pred_lower, ymax = .pred_upper), \n              col = \"orange\", linewidth = 1, fill = NA)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/split-pred-plit-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoverage <- function(x) {\n  x %>% \n    mutate(in_bound = .pred_lower < y & .pred_upper > y) %>% \n    summarise(coverage = mean(in_bound))\n}\ncoverage(test_split_res)\n#> # A tibble: 1 × 1\n#>   coverage\n#>      <dbl>\n#> 1    0.930\n```\n:::\n\n\n## Resampling\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(493)\nfolds <- vfold_cv(train_data)\n\nctrl <- control_resamples(save_pred = TRUE, extract = I)\nnnet_rs <- \n  nnet_wflow %>% \n  fit_resamples(folds, control = ctrl)\n\ncollect_metrics(nnet_rs)\n#> # A tibble: 2 × 6\n#>   .metric .estimator  mean     n std_err .config             \n#>   <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   0.201    10 0.00524 Preprocessor1_Model1\n#> 2 rsq     standard   0.950    10 0.00447 Preprocessor1_Model1\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv_int <- int_conformal_infer_cv(nnet_rs)\ncv_int\n#> Conformal inference via CV+\n#> preprocessor: formula \n#> model: mlp (engine = nnet) \n#> number of models: 10 \n#> training set size: 1,000 \n#> \n#> Use `predict(object, new_data, level)` to compute prediction intervals\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Produce 90% prediction intervals\ntest_cv_res <- \n  predict(cv_int, test_data, level = 0.90) %>% \n  bind_cols(test_data)\n\ntest_cv_res %>% \n  ggplot(aes(x)) +\n  geom_point(aes(y = y), alpha = 1 / 20) +\n  geom_line(\n    data = nnet_pred, aes(y = .pred),\n    linewidth = 1, col = \"blue\"\n  ) +\n  geom_ribbon(aes(ymin = .pred_lower, ymax = .pred_upper), \n              col = \"orange\", linewidth = 1, fill = NA)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/cv-pred-1.svg){fig-align='center' width=70%}\n:::\n\n```{.r .cell-code}\n\ncoverage(test_cv_res)\n#> # A tibble: 1 × 1\n#>   coverage\n#>      <dbl>\n#> 1    0.896\n```\n:::\n\n\n## Adaptive width intervals\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmake_variable_data <- function(n, std_dev = 1 / 5) {\n  tibble(x = runif(n, min = -1)) %>%\n    mutate(\n      y = (x^3) + 2 * exp(-6 * (x - 0.3)^2),\n      y = y + rnorm(n, sd = std_dev * abs(x))\n    )\n}\n\nmake_variable_data(1000) %>% \n  ggplot(aes(x, y)) + \n  geom_point(alpha = 1 / 5)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/variable-plot-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(7292)\ntrain_variable_data  <- make_variable_data(n)\ncal_variable_data  <- make_variable_data(250)\ntest_variable_data <- make_variable_data(10000)\n\nnnet_variable_fit <- nnet_wflow %>% fit(train_variable_data)\nnnet_variable_pred <- augment(nnet_variable_fit, train_variable_data)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquant_int <-\n  int_conformal_infer_quantile(\n    nnet_variable_fit, \n    train_data = train_variable_data,\n    cal_data = cal_variable_data, \n    level = 0.90,\n    ntree = 2000)\nquant_int\n#> Split Conformal inference via Quantile Regression\n#> preprocessor: formula \n#> model: mlp (engine = nnet) \n#> calibration set size: 250 \n#> confidence level: 0.9 \n#> \n#> Use `predict(object, new_data)` to compute prediction intervals\n\ntest_quant_res <- \n  predict(quant_int, test_variable_data) %>% \n  bind_cols(test_variable_data)\n\ncoverage(test_quant_res)\n#> # A tibble: 1 × 1\n#>   coverage\n#>      <dbl>\n#> 1    0.910\n```\n:::\n\n\nThe results: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntest_quant_res %>% \n  ggplot(aes(x)) +\n  geom_point(aes(y = y), alpha = 1 / 20) +\n  geom_line(\n    data = nnet_variable_pred, aes(y = .pred),\n    linewidth = 1, col = \"blue\"\n  ) +\n  geom_ribbon(aes(ymin = .pred_lower, ymax = .pred_upper), \n              col = \"orange\", linewidth = 1, fill = NA)\n```\n\n::: {.cell-output-display}\n![](conformal_files/figure-html/quant-pred-plit-1.svg){fig-align='center' width=70%}\n:::\n:::\n",
    "supporting": [
      "conformal_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}